{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_dic(dic, ix = None, p = None, n = 0, g = 0):\n",
    "    if ix == None:\n",
    "        ix = dict()\n",
    "    \n",
    "    nz = n * g\n",
    "    col_ix = np.empty(nz, dtype = int)\n",
    "    \n",
    "    i = 0\n",
    "    for k, lis in dic.items():\n",
    "        for t in range(len(lis)):\n",
    "            ix[str(lis[t]) + str(k)] = ix.get(str(lis[t]) + str(k), 0) + 1\n",
    "            col_ix[i + t*g] = ix[str(lis[t]) + str(k)]\n",
    "        i += 1\n",
    "    row_ix = np.repeat(np.arange(0, n), g)\n",
    "    data = np.ones(nz)\n",
    "    if p == None:\n",
    "        p = len(ix)\n",
    "    \n",
    "    ixx = np.where(col_ix < p)\n",
    "    return csr.csr_matrix((data[ixx], (row_ix[ixx], col_ix[ixx])), shape = (n, p)), ix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "row =  [\"hello\", \"world\", \"hello\"]\n",
    "col =  [\"goodbye\", \"cruel\", \"world\"]\n",
    "x, ix = vectorize_dic({'users': row, 'items': col}, n = len(row), g = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher(X_, y_ = None, batch_size = -1):\n",
    "    n_samples = X_.shape[0]\n",
    "    \n",
    "    if batch_size == -1:\n",
    "        batch_size = n_samples\n",
    "    if batch_size < 1:\n",
    "        raise ValueError('parameter batchsize is unsupported')\n",
    "        \n",
    "    for i in range(0, n_samples, batch_size):\n",
    "        upper_bound = min(i + batch_size, n_samples)\n",
    "        ret_x = X_[i: upper_bound]\n",
    "        ret_y = None\n",
    "        if y_ is not None:\n",
    "            ret_y = y_[i: i + batch_size]\n",
    "            yield(ret_x, ret_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['user','item','rating','timestamp']\n",
    "\n",
    "train = pd.read_csv('ua.base',delimiter='\\t',names = cols)\n",
    "test = pd.read_csv('ua.test',delimiter='\\t',names = cols)\n",
    "\n",
    "x_train, ix = vectorize_dic({'users': train['user'].values, 'items': train['item'].values}, n = len(train.index), g = 2)\n",
    "x_test, ix = vectorize_dic({'users': test['user'].values, 'items': test['item'].values}, ix, x_train.shape[1], n = len(test.index), g = 2)\n",
    "\n",
    "y_train = train['rating'].values\n",
    "y_test = test['rating'].values\n",
    "\n",
    "x_train = x_train.todense()\n",
    "x_test = x_test.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90570, 2623)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9430, 2623)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p = x_train.shape\n",
    "k = 10\n",
    "x = tf.placeholder('float', [None, p])\n",
    "y = tf.placeholder('float', [None, 1])\n",
    "\n",
    "w0 = tf.Variable(tf.zeros([1]))\n",
    "w = tf.Variable(tf.zeros([p]))\n",
    "\n",
    "v = tf.Variable(tf.random_normal([k, p], mean = 0, stddev = 0.01)) #二维\n",
    "\n",
    "linear_terms = tf.add(w0, tf.reduce_sum(tf.multiply(w, x), 1, keep_dims = True))#tf.multiply对应位置相乘\n",
    "\n",
    "pair_interactions = 0.5 * tf.reduce_sum(\n",
    "    tf.subtract(\n",
    "        tf.pow(\n",
    "            tf.matmul(x, tf.transpose(v)), 2),#tf.transpose()对于二维数组相当于转至\n",
    "        tf.matmul(tf.pow(x, 2), tf.transpose(tf.pow(v, 2)))#tf.matmul矩阵乘法\n",
    "    ), axis = 1, keep_dims = True)\n",
    "\n",
    "y_hat = tf.add(linear_terms, pair_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_w = tf.constant(0.001, name = 'lambda_w')\n",
    "lambda_v = tf.constant(0.001, name = 'lambda_v')\n",
    "\n",
    "l2_norm = tf.reduce_sum(\n",
    "    tf.add(\n",
    "        tf.multiply(lambda_w, tf.pow(w, 2)), \n",
    "        tf.multiply(lambda_v, tf.pow(v, 2))\n",
    "    )\n",
    ")\n",
    "\n",
    "error = tf.reduce_mean(tf.square(y - y_hat))#对每一个数求平方\n",
    "loss = tf.add(error, l2_norm)\n",
    "\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba6520ebfb145f08232bc14bb82ab6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.1251887\n",
      "[array([[3.50187  ],\n",
      "       [3.4885578],\n",
      "       [3.5098734],\n",
      "       ...,\n",
      "       [3.5195694],\n",
      "       [3.518788 ],\n",
      "       [3.5150516]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 1000\n",
    "predictions = []\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), unit = 'epoch'):\n",
    "        perm = np.random.permutation(x_train.shape[0])\n",
    "        for bX, bY in batcher(x_train[perm], y_train[perm], batch_size):\n",
    "            _, t = sess.run([train_op, loss], feed_dict = {x: bX.reshape(-1, p), y: bY.reshape(-1, 1)})\n",
    "#             print(t)\n",
    "            \n",
    "    errors = []\n",
    "    for bX, bY in batcher(x_test, y_test):\n",
    "        errors.append(sess.run(error, feed_dict = {x: bX.reshape(-1, p), y: bY.reshape(-1, 1)}))\n",
    "        predictions.append(sess.run(y_hat, feed_dict = {x: bX.reshape(-1, p), y: bY.reshape(-1, 1)}))\n",
    "#         print(errors)\n",
    "    RMSE = np.sqrt(np.array(errors).mean())\n",
    "    print(RMSE)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"users\": test.user.values})\n",
    "submission['rating'] = predictions[0]\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[3.50187  ],\n",
      "       [3.4885578],\n",
      "       [3.5098734],\n",
      "       ...,\n",
      "       [3.5195694],\n",
      "       [3.518788 ],\n",
      "       [3.5150516]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
